{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "643a87c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n",
    "import time\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "483eb728",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('chromedriver.exe')  #intiating the chrome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d9e7b9",
   "metadata": {},
   "source": [
    "1. Scrape the details of most viewed videos on YouTube from Wikipedia.\n",
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\n",
    "You need to find following details:\n",
    "A) Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f479599b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76a60b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank=[]\n",
    "name=[]\n",
    "artist=[]\n",
    "views=[]\n",
    "upload=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92c03ec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Views(billions)</th>\n",
       "      <th>Upload Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Baby Shark Dance\"[4]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>7,046,700,000</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>November 2, 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Despacito\"[7]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>2,993,700,000</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>August 4, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"See You Again\"[18]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>2,894,000,000</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>July 10, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Gangnam Style\"⁂[27]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>803,700,000</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>November 24, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Baby\"*[63]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>245,400,000</td>\n",
       "      <td>February 19, 2010</td>\n",
       "      <td>July 16, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"Bad Romance\"[67]</td>\n",
       "      <td>Lady Gaga</td>\n",
       "      <td>178,400,000</td>\n",
       "      <td>November 24, 2009</td>\n",
       "      <td>April 14, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"Charlie Bit My Finger\"‡[71]</td>\n",
       "      <td>HDCYT</td>\n",
       "      <td>128,900,000</td>\n",
       "      <td>May 22, 2007</td>\n",
       "      <td>October 25, 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"Evolution of Dance\"[74]</td>\n",
       "      <td>Judson Laipply</td>\n",
       "      <td>118,900,000</td>\n",
       "      <td>April 6, 2006</td>\n",
       "      <td>May 2, 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"Girlfriend\"‡[76][77]</td>\n",
       "      <td>RCA Records</td>\n",
       "      <td>92,600,000</td>\n",
       "      <td>February 27, 2007</td>\n",
       "      <td>July 17, 2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"Evolution of Dance\"[74]</td>\n",
       "      <td>Judson Laipply</td>\n",
       "      <td>78,400,000</td>\n",
       "      <td>April 6, 2006</td>\n",
       "      <td>March 15, 2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>\"Music Is My Hot Hot Sex\"‡[81]</td>\n",
       "      <td>CLARUSBARTEL72</td>\n",
       "      <td>76,600,000</td>\n",
       "      <td>April 9, 2007</td>\n",
       "      <td>March 1, 2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>\"Evolution of Dance\"*[74]</td>\n",
       "      <td>Judson Laipply</td>\n",
       "      <td>10,600,000</td>\n",
       "      <td>April 6, 2006</td>\n",
       "      <td>May 19, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>\"Pokémon Theme Music Video\"‡[87]</td>\n",
       "      <td>Smosh</td>\n",
       "      <td>4,300,000</td>\n",
       "      <td>November 28, 2005</td>\n",
       "      <td>March 12, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>\"Myspace – The Movie\"‡[92][93]</td>\n",
       "      <td>eggtea</td>\n",
       "      <td>2,700,000</td>\n",
       "      <td>January 31, 2006</td>\n",
       "      <td>February 18, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>\"Phony Photo Booth\"‡[96]</td>\n",
       "      <td>mugenized</td>\n",
       "      <td>3,400,000</td>\n",
       "      <td>December 1, 2005</td>\n",
       "      <td>January 21, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>\"The Chronic of Narnia Rap\"‡[98]</td>\n",
       "      <td>youtubedude</td>\n",
       "      <td>2,300,000</td>\n",
       "      <td>December 18, 2005</td>\n",
       "      <td>January 9, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>\"Ronaldinho: Touch of Gold\"‡*[100]</td>\n",
       "      <td>Nikesoccer</td>\n",
       "      <td>255,000</td>\n",
       "      <td>October 21, 2005</td>\n",
       "      <td>October 31, 2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>\"I/O Brush\"‡*[103]</td>\n",
       "      <td>larfus</td>\n",
       "      <td>247,000</td>\n",
       "      <td>October 5, 2005</td>\n",
       "      <td>October 29, 2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>\"Me at the zoo\"[105]</td>\n",
       "      <td>jawed</td>\n",
       "      <td>1</td>\n",
       "      <td>April 23, 2005</td>\n",
       "      <td>April 23, 2005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Rank  \\\n",
       "0                \"Baby Shark Dance\"[4]   \n",
       "1                       \"Despacito\"[7]   \n",
       "2                  \"See You Again\"[18]   \n",
       "3                 \"Gangnam Style\"⁂[27]   \n",
       "4                          \"Baby\"*[63]   \n",
       "5                    \"Bad Romance\"[67]   \n",
       "6         \"Charlie Bit My Finger\"‡[71]   \n",
       "7             \"Evolution of Dance\"[74]   \n",
       "8                \"Girlfriend\"‡[76][77]   \n",
       "9             \"Evolution of Dance\"[74]   \n",
       "10      \"Music Is My Hot Hot Sex\"‡[81]   \n",
       "11           \"Evolution of Dance\"*[74]   \n",
       "12    \"Pokémon Theme Music Video\"‡[87]   \n",
       "13      \"Myspace – The Movie\"‡[92][93]   \n",
       "14            \"Phony Photo Booth\"‡[96]   \n",
       "15    \"The Chronic of Narnia Rap\"‡[98]   \n",
       "16  \"Ronaldinho: Touch of Gold\"‡*[100]   \n",
       "17                  \"I/O Brush\"‡*[103]   \n",
       "18                \"Me at the zoo\"[105]   \n",
       "\n",
       "                                           Name         Artist  \\\n",
       "0   Pinkfong Baby Shark - Kids' Songs & Stories  7,046,700,000   \n",
       "1                                    Luis Fonsi  2,993,700,000   \n",
       "2                                   Wiz Khalifa  2,894,000,000   \n",
       "3                                           Psy    803,700,000   \n",
       "4                                 Justin Bieber    245,400,000   \n",
       "5                                     Lady Gaga    178,400,000   \n",
       "6                                         HDCYT    128,900,000   \n",
       "7                                Judson Laipply    118,900,000   \n",
       "8                                   RCA Records     92,600,000   \n",
       "9                                Judson Laipply     78,400,000   \n",
       "10                               CLARUSBARTEL72     76,600,000   \n",
       "11                               Judson Laipply     10,600,000   \n",
       "12                                        Smosh      4,300,000   \n",
       "13                                       eggtea      2,700,000   \n",
       "14                                    mugenized      3,400,000   \n",
       "15                                  youtubedude      2,300,000   \n",
       "16                                   Nikesoccer        255,000   \n",
       "17                                       larfus        247,000   \n",
       "18                                        jawed              1   \n",
       "\n",
       "      Views(billions)        Upload Date  \n",
       "0       June 17, 2016   November 2, 2020  \n",
       "1    January 12, 2017     August 4, 2017  \n",
       "2       April 6, 2015      July 10, 2017  \n",
       "3       July 15, 2012  November 24, 2012  \n",
       "4   February 19, 2010      July 16, 2010  \n",
       "5   November 24, 2009     April 14, 2010  \n",
       "6        May 22, 2007   October 25, 2009  \n",
       "7       April 6, 2006        May 2, 2009  \n",
       "8   February 27, 2007      July 17, 2008  \n",
       "9       April 6, 2006     March 15, 2008  \n",
       "10      April 9, 2007      March 1, 2008  \n",
       "11      April 6, 2006       May 19, 2006  \n",
       "12  November 28, 2005     March 12, 2006  \n",
       "13   January 31, 2006  February 18, 2006  \n",
       "14   December 1, 2005   January 21, 2006  \n",
       "15  December 18, 2005    January 9, 2006  \n",
       "16   October 21, 2005   October 31, 2005  \n",
       "17    October 5, 2005   October 29, 2005  \n",
       "18     April 23, 2005     April 23, 2005  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in driver.find_elements(By.XPATH, '//table[3]//tbody//tr//td[1]'):\n",
    "    rank.append(i.text)\n",
    "    \n",
    "for i in driver.find_elements(By.XPATH, '//table[3]//tbody//tr//td[2]'):\n",
    "    name.append(i.text)\n",
    "    \n",
    "for i in driver.find_elements(By.XPATH, '//table[3]//tbody//tr//td[3]'):\n",
    "    artist.append(i.text)\n",
    "    \n",
    "for i in driver.find_elements(By.XPATH,'//table[3]//tbody//tr//td[4]'):\n",
    "    views.append(i.text)\n",
    "    \n",
    "for i in driver.find_elements(By.XPATH,'//table[3]//tbody//tr//td[5]'):\n",
    "    upload.append(i.text)\n",
    "    \n",
    "    \n",
    "que1=pd.DataFrame({'Rank':rank,'Name':name,'Artist':artist,'Views(billions)':views,'Upload Date':upload})\n",
    "que1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3929c28b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Views(billions)</th>\n",
       "      <th>Upload Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Baby Shark Dance\"[4]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>7,046,700,000</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>November 2, 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Despacito\"[7]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>2,993,700,000</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>August 4, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"See You Again\"[18]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>2,894,000,000</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>July 10, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Gangnam Style\"⁂[27]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>803,700,000</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>November 24, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Baby\"*[63]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>245,400,000</td>\n",
       "      <td>February 19, 2010</td>\n",
       "      <td>July 16, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"Bad Romance\"[67]</td>\n",
       "      <td>Lady Gaga</td>\n",
       "      <td>178,400,000</td>\n",
       "      <td>November 24, 2009</td>\n",
       "      <td>April 14, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"Charlie Bit My Finger\"‡[71]</td>\n",
       "      <td>HDCYT</td>\n",
       "      <td>128,900,000</td>\n",
       "      <td>May 22, 2007</td>\n",
       "      <td>October 25, 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"Evolution of Dance\"[74]</td>\n",
       "      <td>Judson Laipply</td>\n",
       "      <td>118,900,000</td>\n",
       "      <td>April 6, 2006</td>\n",
       "      <td>May 2, 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"Girlfriend\"‡[76][77]</td>\n",
       "      <td>RCA Records</td>\n",
       "      <td>92,600,000</td>\n",
       "      <td>February 27, 2007</td>\n",
       "      <td>July 17, 2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"Evolution of Dance\"[74]</td>\n",
       "      <td>Judson Laipply</td>\n",
       "      <td>78,400,000</td>\n",
       "      <td>April 6, 2006</td>\n",
       "      <td>March 15, 2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>\"Music Is My Hot Hot Sex\"‡[81]</td>\n",
       "      <td>CLARUSBARTEL72</td>\n",
       "      <td>76,600,000</td>\n",
       "      <td>April 9, 2007</td>\n",
       "      <td>March 1, 2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>\"Evolution of Dance\"*[74]</td>\n",
       "      <td>Judson Laipply</td>\n",
       "      <td>10,600,000</td>\n",
       "      <td>April 6, 2006</td>\n",
       "      <td>May 19, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>\"Pokémon Theme Music Video\"‡[87]</td>\n",
       "      <td>Smosh</td>\n",
       "      <td>4,300,000</td>\n",
       "      <td>November 28, 2005</td>\n",
       "      <td>March 12, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>\"Myspace – The Movie\"‡[92][93]</td>\n",
       "      <td>eggtea</td>\n",
       "      <td>2,700,000</td>\n",
       "      <td>January 31, 2006</td>\n",
       "      <td>February 18, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>\"Phony Photo Booth\"‡[96]</td>\n",
       "      <td>mugenized</td>\n",
       "      <td>3,400,000</td>\n",
       "      <td>December 1, 2005</td>\n",
       "      <td>January 21, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>\"The Chronic of Narnia Rap\"‡[98]</td>\n",
       "      <td>youtubedude</td>\n",
       "      <td>2,300,000</td>\n",
       "      <td>December 18, 2005</td>\n",
       "      <td>January 9, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>\"Ronaldinho: Touch of Gold\"‡*[100]</td>\n",
       "      <td>Nikesoccer</td>\n",
       "      <td>255,000</td>\n",
       "      <td>October 21, 2005</td>\n",
       "      <td>October 31, 2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>\"I/O Brush\"‡*[103]</td>\n",
       "      <td>larfus</td>\n",
       "      <td>247,000</td>\n",
       "      <td>October 5, 2005</td>\n",
       "      <td>October 29, 2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>\"Me at the zoo\"[105]</td>\n",
       "      <td>jawed</td>\n",
       "      <td>1</td>\n",
       "      <td>April 23, 2005</td>\n",
       "      <td>April 23, 2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.</td>\n",
       "      <td>Baby Shark Dance</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>12.13</td>\n",
       "      <td>June 17, 2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Rank  \\\n",
       "0                \"Baby Shark Dance\"[4]   \n",
       "1                       \"Despacito\"[7]   \n",
       "2                  \"See You Again\"[18]   \n",
       "3                 \"Gangnam Style\"⁂[27]   \n",
       "4                          \"Baby\"*[63]   \n",
       "5                    \"Bad Romance\"[67]   \n",
       "6         \"Charlie Bit My Finger\"‡[71]   \n",
       "7             \"Evolution of Dance\"[74]   \n",
       "8                \"Girlfriend\"‡[76][77]   \n",
       "9             \"Evolution of Dance\"[74]   \n",
       "10      \"Music Is My Hot Hot Sex\"‡[81]   \n",
       "11           \"Evolution of Dance\"*[74]   \n",
       "12    \"Pokémon Theme Music Video\"‡[87]   \n",
       "13      \"Myspace – The Movie\"‡[92][93]   \n",
       "14            \"Phony Photo Booth\"‡[96]   \n",
       "15    \"The Chronic of Narnia Rap\"‡[98]   \n",
       "16  \"Ronaldinho: Touch of Gold\"‡*[100]   \n",
       "17                  \"I/O Brush\"‡*[103]   \n",
       "18                \"Me at the zoo\"[105]   \n",
       "19                                  1.   \n",
       "\n",
       "                                           Name  \\\n",
       "0   Pinkfong Baby Shark - Kids' Songs & Stories   \n",
       "1                                    Luis Fonsi   \n",
       "2                                   Wiz Khalifa   \n",
       "3                                           Psy   \n",
       "4                                 Justin Bieber   \n",
       "5                                     Lady Gaga   \n",
       "6                                         HDCYT   \n",
       "7                                Judson Laipply   \n",
       "8                                   RCA Records   \n",
       "9                                Judson Laipply   \n",
       "10                               CLARUSBARTEL72   \n",
       "11                               Judson Laipply   \n",
       "12                                        Smosh   \n",
       "13                                       eggtea   \n",
       "14                                    mugenized   \n",
       "15                                  youtubedude   \n",
       "16                                   Nikesoccer   \n",
       "17                                       larfus   \n",
       "18                                        jawed   \n",
       "19                             Baby Shark Dance   \n",
       "\n",
       "                                         Artist    Views(billions)  \\\n",
       "0                                 7,046,700,000      June 17, 2016   \n",
       "1                                 2,993,700,000   January 12, 2017   \n",
       "2                                 2,894,000,000      April 6, 2015   \n",
       "3                                   803,700,000      July 15, 2012   \n",
       "4                                   245,400,000  February 19, 2010   \n",
       "5                                   178,400,000  November 24, 2009   \n",
       "6                                   128,900,000       May 22, 2007   \n",
       "7                                   118,900,000      April 6, 2006   \n",
       "8                                    92,600,000  February 27, 2007   \n",
       "9                                    78,400,000      April 6, 2006   \n",
       "10                                   76,600,000      April 9, 2007   \n",
       "11                                   10,600,000      April 6, 2006   \n",
       "12                                    4,300,000  November 28, 2005   \n",
       "13                                    2,700,000   January 31, 2006   \n",
       "14                                    3,400,000   December 1, 2005   \n",
       "15                                    2,300,000  December 18, 2005   \n",
       "16                                      255,000   October 21, 2005   \n",
       "17                                      247,000    October 5, 2005   \n",
       "18                                            1     April 23, 2005   \n",
       "19  Pinkfong Baby Shark - Kids' Songs & Stories              12.13   \n",
       "\n",
       "          Upload Date  \n",
       "0    November 2, 2020  \n",
       "1      August 4, 2017  \n",
       "2       July 10, 2017  \n",
       "3   November 24, 2012  \n",
       "4       July 16, 2010  \n",
       "5      April 14, 2010  \n",
       "6    October 25, 2009  \n",
       "7         May 2, 2009  \n",
       "8       July 17, 2008  \n",
       "9      March 15, 2008  \n",
       "10      March 1, 2008  \n",
       "11       May 19, 2006  \n",
       "12     March 12, 2006  \n",
       "13  February 18, 2006  \n",
       "14   January 21, 2006  \n",
       "15    January 9, 2006  \n",
       "16   October 31, 2005  \n",
       "17   October 29, 2005  \n",
       "18     April 23, 2005  \n",
       "19      June 17, 2016  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# By copying full x-path. \n",
    "\n",
    "for i in driver.find_elements(By.XPATH, '/html/body/div[1]/div/div[3]/main/div[2]/div[3]/div[1]/table[2]/tbody/tr[1]/td[1]'):\n",
    "    rank.append(i.text)\n",
    "    \n",
    "for i in driver.find_elements(By.XPATH, '/html/body/div[1]/div/div[3]/main/div[2]/div[3]/div[1]/table[2]/tbody/tr[1]/td[2]/a'):\n",
    "    name.append(i.text)\n",
    "    \n",
    "for i in driver.find_elements(By.XPATH, '/html/body/div[1]/div/div[3]/main/div[2]/div[3]/div[1]/table[2]/tbody/tr[1]/td[3]/a'):\n",
    "    artist.append(i.text)\n",
    "    \n",
    "for i in driver.find_elements(By.XPATH,'/html/body/div[1]/div/div[3]/main/div[2]/div[3]/div[1]/table[2]/tbody/tr[1]/td[4]'):\n",
    "    views.append(i.text)\n",
    "    \n",
    "for i in driver.find_elements(By.XPATH,'/html/body/div[1]/div/div[3]/main/div[2]/div[3]/div[1]/table[2]/tbody/tr[1]/td[5]'):\n",
    "    upload.append(i.text)\n",
    "    \n",
    "    \n",
    "que1=pd.DataFrame({'Rank':rank,'Name':name,'Artist':artist,'Views(billions)':views,'Upload Date':upload})\n",
    "que1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db09695",
   "metadata": {},
   "source": [
    "2. Scrape the details team India’s internationalfixtures from bcci.tv. \n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Match title (I.e. 1stODI)\n",
    "B) Series\n",
    "C) Place\n",
    "D) Date\n",
    "E) Time\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86c280c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.bcci.tv/'\n",
    "driver.get(url)\n",
    "driver.maximize_window() # For full size window. \n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8efa3e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking on fixtures option. \n",
    "\n",
    "intn=driver.find_element(By.XPATH, '/html/body/nav/div/div[2]/ul[1]/li[2]/a')\n",
    "intn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e948d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match Title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1st Test -</td>\n",
       "      <td>AUSTRALIA TOUR OF INDIA TEST SERIES 2022-23</td>\n",
       "      <td>Vidarbha Cricket Association Stadium, Nagpur</td>\n",
       "      <td>9 FEB 2023</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1st T20I -</td>\n",
       "      <td>ICC WOMENS T20 WORLD CUP 2023</td>\n",
       "      <td>Newlands, Cape Town</td>\n",
       "      <td>12 FEB 2023</td>\n",
       "      <td>6:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2nd T20I -</td>\n",
       "      <td>ICC WOMENS T20 WORLD CUP 2023</td>\n",
       "      <td>Newlands, Cape Town</td>\n",
       "      <td>15 FEB 2023</td>\n",
       "      <td>6:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2nd Test -</td>\n",
       "      <td>AUSTRALIA TOUR OF INDIA TEST SERIES 2022-23</td>\n",
       "      <td>Arun Jaitley Stadium, Delhi</td>\n",
       "      <td>17 FEB 2023</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3rd T20I -</td>\n",
       "      <td>ICC WOMENS T20 WORLD CUP 2023</td>\n",
       "      <td>St George's Park, Gqeberha</td>\n",
       "      <td>18 FEB 2023</td>\n",
       "      <td>6:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4th T20I -</td>\n",
       "      <td>ICC WOMENS T20 WORLD CUP 2023</td>\n",
       "      <td>St George's Park, Gqeberha</td>\n",
       "      <td>20 FEB 2023</td>\n",
       "      <td>6:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3rd Test -</td>\n",
       "      <td>AUSTRALIA TOUR OF INDIA TEST SERIES 2022-23</td>\n",
       "      <td>Himachal Pradesh Cricket Association Stadium,...</td>\n",
       "      <td>1 MAR 2023</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4th Test -</td>\n",
       "      <td>AUSTRALIA TOUR OF INDIA TEST SERIES 2022-23</td>\n",
       "      <td>Narendra Modi Stadium, Ahmedabad</td>\n",
       "      <td>9 MAR 2023</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Match Title                                       Series  \\\n",
       "0  1st Test -  AUSTRALIA TOUR OF INDIA TEST SERIES 2022-23   \n",
       "1  1st T20I -                ICC WOMENS T20 WORLD CUP 2023   \n",
       "2  2nd T20I -                ICC WOMENS T20 WORLD CUP 2023   \n",
       "3  2nd Test -  AUSTRALIA TOUR OF INDIA TEST SERIES 2022-23   \n",
       "4  3rd T20I -                ICC WOMENS T20 WORLD CUP 2023   \n",
       "5  4th T20I -                ICC WOMENS T20 WORLD CUP 2023   \n",
       "6  3rd Test -  AUSTRALIA TOUR OF INDIA TEST SERIES 2022-23   \n",
       "7  4th Test -  AUSTRALIA TOUR OF INDIA TEST SERIES 2022-23   \n",
       "\n",
       "                                               Place         Date         Time  \n",
       "0       Vidarbha Cricket Association Stadium, Nagpur   9 FEB 2023  9:30 AM IST  \n",
       "1                                Newlands, Cape Town  12 FEB 2023  6:30 PM IST  \n",
       "2                                Newlands, Cape Town  15 FEB 2023  6:30 PM IST  \n",
       "3                        Arun Jaitley Stadium, Delhi  17 FEB 2023  9:30 AM IST  \n",
       "4                         St George's Park, Gqeberha  18 FEB 2023  6:30 PM IST  \n",
       "5                         St George's Park, Gqeberha  20 FEB 2023  6:30 PM IST  \n",
       "6   Himachal Pradesh Cricket Association Stadium,...   1 MAR 2023  9:30 AM IST  \n",
       "7                   Narendra Modi Stadium, Ahmedabad   9 MAR 2023  9:30 AM IST  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title=[]\n",
    "for i in driver.find_elements(By.XPATH, '//span[@class=\"matchOrderText ng-binding ng-scope\"]'):\n",
    "    title.append(i.text)\n",
    "    \n",
    "series=[]\n",
    "for i in driver.find_elements(By.XPATH, '//h5[@class=\"fix-text\"]//span[@class=\"ng-binding\"]'):\n",
    "    series.append(i.text)\n",
    "    \n",
    "place=[]\n",
    "for i in driver.find_elements(By.XPATH, '//div[@class=\"fix-place ng-binding ng-scope\"]'):\n",
    "    place.append(i.text.split(\"-\")[1])\n",
    "    \n",
    "date=[]\n",
    "for i in driver.find_elements(By.XPATH, '//div[@class=\"match-card-left match-schedule\"]//h5'):\n",
    "    date.append(i.text)\n",
    "    \n",
    "time=[]\n",
    "for i in driver.find_elements(By.XPATH, '//div[@class=\"match-card-right match-schedule \"]//h5'):\n",
    "    time.append(i.text)\n",
    "    \n",
    "que2=pd.DataFrame({'Match Title':title,'Series':series,'Place':place,'Date':date,'Time':time})\n",
    "que2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33004e13",
   "metadata": {},
   "source": [
    "3. Scrape the details of State-wise GDP of India from statisticstime.com. \n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details:\n",
    "A) Rank\n",
    "B) State\n",
    "C) GSDP(18-19)- at current prices\n",
    "D) GSDP(19-20)- at current prices\n",
    "E) Share(18-19)\n",
    "F) GDP($ billion)\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04e50d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='http://statisticstimes.com/'\n",
    "driver.get(url)\n",
    "from selenium.webdriver.support.ui import Select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "705f9945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click on economy button then click on india button in it. \n",
    "\n",
    "driver.find_element(By.XPATH, '/html/body/div[2]/div[1]/div[2]/div[2]/button').click()\n",
    "driver.find_element(By.LINK_TEXT, 'India').click()\n",
    "try:\n",
    "    add=driver.find_element_by_id(\"dismiss-button\")\n",
    "    add.click()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a034a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP(19-20)</th>\n",
       "      <th>GSDP(18-19)</th>\n",
       "      <th>Share(18-19)</th>\n",
       "      <th>GDP($billion)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>942,586</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>972,782</td>\n",
       "      <td>862,957</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>969,604</td>\n",
       "      <td>861,031</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>906,672</td>\n",
       "      <td>809,592</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>-</td>\n",
       "      <td>781,653</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>856,112</td>\n",
       "      <td>774,870</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>831,610</td>\n",
       "      <td>734,163</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>611,804</td>\n",
       "      <td>530,363</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>574,760</td>\n",
       "      <td>526,376</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>521,275</td>\n",
       "      <td>487,805</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>-</td>\n",
       "      <td>315,881</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>329,180</td>\n",
       "      <td>304,063</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>328,598</td>\n",
       "      <td>297,204</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>-</td>\n",
       "      <td>245,895</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>-</td>\n",
       "      <td>155,956</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>165,472</td>\n",
       "      <td>153,845</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>80,449</td>\n",
       "      <td>73,170</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>55,984</td>\n",
       "      <td>49,845</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>-</td>\n",
       "      <td>42,114</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>38,253</td>\n",
       "      <td>34,433</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>36,572</td>\n",
       "      <td>33,481</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>32,496</td>\n",
       "      <td>28,723</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>31,790</td>\n",
       "      <td>27,870</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>-</td>\n",
       "      <td>27,283</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>-</td>\n",
       "      <td>24,603</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>26,503</td>\n",
       "      <td>22,287</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State GSDP(19-20) GSDP(18-19) Share(18-19)  \\\n",
       "0     1                Maharashtra           -   2,632,792       13.94%   \n",
       "1     2                 Tamil Nadu   1,845,853   1,630,208        8.63%   \n",
       "2     3              Uttar Pradesh   1,687,818   1,584,764        8.39%   \n",
       "3     4                    Gujarat           -   1,502,899        7.96%   \n",
       "4     5                  Karnataka   1,631,977   1,493,127        7.91%   \n",
       "5     6                West Bengal   1,253,832   1,089,898        5.77%   \n",
       "6     7                  Rajasthan   1,020,989     942,586        4.99%   \n",
       "7     8             Andhra Pradesh     972,782     862,957        4.57%   \n",
       "8     9                  Telangana     969,604     861,031        4.56%   \n",
       "9    10             Madhya Pradesh     906,672     809,592        4.29%   \n",
       "10   11                     Kerala           -     781,653        4.14%   \n",
       "11   12                      Delhi     856,112     774,870        4.10%   \n",
       "12   13                    Haryana     831,610     734,163        3.89%   \n",
       "13   14                      Bihar     611,804     530,363        2.81%   \n",
       "14   15                     Punjab     574,760     526,376        2.79%   \n",
       "15   16                     Odisha     521,275     487,805        2.58%   \n",
       "16   17                      Assam           -     315,881        1.67%   \n",
       "17   18               Chhattisgarh     329,180     304,063        1.61%   \n",
       "18   19                  Jharkhand     328,598     297,204        1.57%   \n",
       "19   20                Uttarakhand           -     245,895        1.30%   \n",
       "20   21            Jammu & Kashmir           -     155,956        0.83%   \n",
       "21   22           Himachal Pradesh     165,472     153,845        0.81%   \n",
       "22   23                        Goa      80,449      73,170        0.39%   \n",
       "23   24                    Tripura      55,984      49,845        0.26%   \n",
       "24   25                 Chandigarh           -      42,114        0.22%   \n",
       "25   26                 Puducherry      38,253      34,433        0.18%   \n",
       "26   27                  Meghalaya      36,572      33,481        0.18%   \n",
       "27   28                     Sikkim      32,496      28,723        0.15%   \n",
       "28   29                    Manipur      31,790      27,870        0.15%   \n",
       "29   30                   Nagaland           -      27,283        0.14%   \n",
       "30   31          Arunachal Pradesh           -      24,603        0.13%   \n",
       "31   32                    Mizoram      26,503      22,287        0.12%   \n",
       "32   33  Andaman & Nicobar Islands           -           -            -   \n",
       "\n",
       "   GDP($billion)  \n",
       "0        399.921  \n",
       "1        247.629  \n",
       "2        240.726  \n",
       "3        228.290  \n",
       "4        226.806  \n",
       "5        165.556  \n",
       "6        143.179  \n",
       "7        131.083  \n",
       "8        130.791  \n",
       "9        122.977  \n",
       "10       118.733  \n",
       "11       117.703  \n",
       "12       111.519  \n",
       "13        80.562  \n",
       "14        79.957  \n",
       "15        74.098  \n",
       "16        47.982  \n",
       "17        46.187  \n",
       "18        45.145  \n",
       "19        37.351  \n",
       "20        23.690  \n",
       "21        23.369  \n",
       "22        11.115  \n",
       "23         7.571  \n",
       "24         6.397  \n",
       "25         5.230  \n",
       "26         5.086  \n",
       "27         4.363  \n",
       "28         4.233  \n",
       "29         4.144  \n",
       "30         3.737  \n",
       "31         3.385  \n",
       "32             -  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdp=driver.find_element(By.XPATH, '/html/body/div[2]/div[2]/div[2]/ul/li[1]/a') # Clicking on GDP of indian states.\n",
    "gdp.click()\n",
    "\n",
    "rank=[]\n",
    "for i in driver.find_elements(By.XPATH, '/html/body/div[3]/div[2]/div[5]/div[1]/div/table/tbody/tr/td[1]'):\n",
    "    rank.append(i.text)\n",
    "    \n",
    "state=[]\n",
    "for i in driver.find_elements(By.XPATH, '/html/body/div[3]/div[2]/div[5]/div[1]/div/table/tbody/tr/td[2]'):\n",
    "    state.append(i.text)\n",
    "    \n",
    "gdp1=[]\n",
    "for i in driver.find_elements(By.XPATH, '/html/body/div[3]/div[2]/div[5]/div[1]/div/table/tbody/tr/td[3]'):\n",
    "    gdp1.append(i.text)\n",
    "    \n",
    "gdp2=[]\n",
    "for i in driver.find_elements(By.XPATH, '/html/body/div[3]/div[2]/div[5]/div[1]/div/table/tbody/tr/td[4]'):\n",
    "    gdp2.append(i.text)\n",
    "    \n",
    "share=[]\n",
    "for i in driver.find_elements(By.XPATH, '/html/body/div[3]/div[2]/div[5]/div[1]/div/table/tbody/tr/td[5]'):\n",
    "    share.append(i.text)\n",
    "    \n",
    "gdpd=[]\n",
    "for i in driver.find_elements(By.XPATH, '/html/body/div[3]/div[2]/div[5]/div[1]/div/table/tbody/tr/td[6]'):\n",
    "    gdpd.append(i.text)\n",
    "    \n",
    "que4=pd.DataFrame({'Rank':rank,'State':state,'GSDP(19-20)':gdp1,'GSDP(18-19)':gdp2,'Share(18-19)':share,'GDP($billion)':gdpd})\n",
    "que4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2beef806",
   "metadata": {},
   "source": [
    "4. Scrape the details of trending repositories on Github.com. \n",
    "Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc851533",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://github.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "26d3f424",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/button').click()\n",
    "driver.find_element(By.XPATH, '//html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/div/ul[3]/li[3]/a').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6b07d929",
   "metadata": {},
   "outputs": [],
   "source": [
    "title=[]\n",
    "des=[]\n",
    "cont=[]\n",
    "lang=[]\n",
    "     \n",
    "for i in driver.find_elements(By.XPATH, '//h1[@class=\"h3 lh-condensed\"]'):\n",
    "    title.append(i.text)\n",
    "\n",
    "for i in driver.find_elements(By.XPATH, '//p[@class=\"col-9 color-fg-muted my-1 pr-4\"]'):\n",
    "    des.append(i.text)\n",
    "        \n",
    "for i in driver.find_elements(By.XPATH, '//span[@class=\"d-inline-block ml-0 mr-3\"]'):\n",
    "    lang.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "269aae77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e4954d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4b3cec26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef214a6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd17962a",
   "metadata": {},
   "source": [
    "# Let us fill empty values in order to make an data frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "927671dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Language Used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LAION-AI / Open-Assistant</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>acheong08 / ChatGPT</td>\n",
       "      <td>OpenAssistant is a chat-based assistant that u...</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nostr-protocol / nostr</td>\n",
       "      <td>Reverse engineered ChatGPT API</td>\n",
       "      <td>Swift</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>damus-io / damus</td>\n",
       "      <td>a truly censorship-resistant alternative to Tw...</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>microsoft / BioGPT</td>\n",
       "      <td>iOS nostr client</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>waylaidwanderer / node-chatgpt-api</td>\n",
       "      <td>A ChatGPT implementation using the official Ch...</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>yt-dlp / yt-dlp</td>\n",
       "      <td>A youtube-dl fork with additional features and...</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>transitive-bullshit / chatgpt-api</td>\n",
       "      <td>Node.js client for the unofficial ChatGPT API. 🔥</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Datalux / Osintgram</td>\n",
       "      <td>Osintgram is a OSINT tool on Instagram. It off...</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>microsoft / PowerToys</td>\n",
       "      <td>Windows system utilities to maximize productivity</td>\n",
       "      <td>C#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AutumnWhj / ChatGPT-wechat-bot</td>\n",
       "      <td>ChatGPT for wechat https://github.com/AutumnWh...</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>coolsnowwolf / lede</td>\n",
       "      <td>Lean's LEDE source</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Cameri / nostream</td>\n",
       "      <td>A Nostr Relay written in TypeScript</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>hikari-no-yume / touchHLE</td>\n",
       "      <td>High-level emulator for iPhone OS apps</td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ToolJet / ToolJet</td>\n",
       "      <td>Extensible low-code framework for building bus...</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Zero6992 / chatGPT-discord-bot</td>\n",
       "      <td>Integrate ChatGPT into your own discord bot</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>adrianhajdin / project_hoobank</td>\n",
       "      <td>Modern UI/UX website using React.js &amp; Tailwind...</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>dudykr / stc</td>\n",
       "      <td>Speedy TypeScript type checker</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>misskey-dev / misskey</td>\n",
       "      <td>🌎 An interplanetary microblogging platform 🚀</td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>servo / servo</td>\n",
       "      <td>The Servo Browser Engine</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>daveshap / raven</td>\n",
       "      <td>RAVEN (Realtime Assistant Voice Enabled Networ...</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>innnky / so-vits-svc</td>\n",
       "      <td>基于vits与softvc的歌声音色转换模型</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>LeagueOfPoro / CapsuleFarmerEvolved</td>\n",
       "      <td>Automatically drops from lolesports.com and fa...</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>hwchase17 / langchain</td>\n",
       "      <td>⚡ Building applications with LLMs through comp...</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>A-poc / RedTeam-Tools</td>\n",
       "      <td>Tools and Techniques for Red Team / Penetratio...</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Title  \\\n",
       "0             LAION-AI / Open-Assistant   \n",
       "1                   acheong08 / ChatGPT   \n",
       "2                nostr-protocol / nostr   \n",
       "3                      damus-io / damus   \n",
       "4                    microsoft / BioGPT   \n",
       "5    waylaidwanderer / node-chatgpt-api   \n",
       "6                       yt-dlp / yt-dlp   \n",
       "7     transitive-bullshit / chatgpt-api   \n",
       "8                   Datalux / Osintgram   \n",
       "9                 microsoft / PowerToys   \n",
       "10       AutumnWhj / ChatGPT-wechat-bot   \n",
       "11                  coolsnowwolf / lede   \n",
       "12                    Cameri / nostream   \n",
       "13            hikari-no-yume / touchHLE   \n",
       "14                    ToolJet / ToolJet   \n",
       "15       Zero6992 / chatGPT-discord-bot   \n",
       "16       adrianhajdin / project_hoobank   \n",
       "17                         dudykr / stc   \n",
       "18                misskey-dev / misskey   \n",
       "19                        servo / servo   \n",
       "20                     daveshap / raven   \n",
       "21                 innnky / so-vits-svc   \n",
       "22  LeagueOfPoro / CapsuleFarmerEvolved   \n",
       "23                hwchase17 / langchain   \n",
       "24                A-poc / RedTeam-Tools   \n",
       "\n",
       "                                          Description Language Used  \n",
       "0                                       Not Available        Python  \n",
       "1   OpenAssistant is a chat-based assistant that u...        Python  \n",
       "2                      Reverse engineered ChatGPT API         Swift  \n",
       "3   a truly censorship-resistant alternative to Tw...             -  \n",
       "4                                    iOS nostr client        Python  \n",
       "5   A ChatGPT implementation using the official Ch...    JavaScript  \n",
       "6   A youtube-dl fork with additional features and...        Python  \n",
       "7    Node.js client for the unofficial ChatGPT API. 🔥    TypeScript  \n",
       "8   Osintgram is a OSINT tool on Instagram. It off...        Python  \n",
       "9   Windows system utilities to maximize productivity            C#  \n",
       "10  ChatGPT for wechat https://github.com/AutumnWh...    TypeScript  \n",
       "11                                 Lean's LEDE source             C  \n",
       "12                A Nostr Relay written in TypeScript    TypeScript  \n",
       "13             High-level emulator for iPhone OS apps          Rust  \n",
       "14  Extensible low-code framework for building bus...    JavaScript  \n",
       "15        Integrate ChatGPT into your own discord bot             -  \n",
       "16  Modern UI/UX website using React.js & Tailwind...        Python  \n",
       "17                     Speedy TypeScript type checker    JavaScript  \n",
       "18       🌎 An interplanetary microblogging platform 🚀          Rust  \n",
       "19                           The Servo Browser Engine    TypeScript  \n",
       "20  RAVEN (Realtime Assistant Voice Enabled Networ...        Python  \n",
       "21                             基于vits与softvc的歌声音色转换模型        Python  \n",
       "22  Automatically drops from lolesports.com and fa...             -  \n",
       "23  ⚡ Building applications with LLMs through comp...        Python  \n",
       "24  Tools and Techniques for Red Team / Penetratio...        Python  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title=[]\n",
    "des=[]\n",
    "cont=[]\n",
    "lang=[]\n",
    "     \n",
    "for i in driver.find_elements(By.XPATH, '//h1[@class=\"h3 lh-condensed\"]'):\n",
    "    title.append(i.text)\n",
    "\n",
    "for i in driver.find_elements(By.XPATH, '//p[@class=\"col-9 color-fg-muted my-1 pr-4\"]'):\n",
    "    des.append(i.text)\n",
    "        \n",
    "for i in driver.find_elements(By.XPATH, '//span[@class=\"d-inline-block ml-0 mr-3\"]'):\n",
    "    lang.append(i.text)\n",
    "       \n",
    "des.insert(0,'Not Available') # By this way we make this count to 25. \n",
    "lang.insert(3,'-') # Filling empty values by hifen.\n",
    "lang.insert(15,'-') # Filling empty values by hifen.\n",
    "lang.insert(22,'-')  # Filling empty values by hifen.\n",
    "\n",
    "que5=pd.DataFrame({'Title':title,'Description':des,'Language Used':lang})\n",
    "que5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87683b44",
   "metadata": {},
   "source": [
    "5. Scrape the details of top 100 songs on billiboard.com. \n",
    "Url = https:/www.billboard.com/\n",
    "You have to find the following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0de37709",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https:/www.billboard.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1ea62f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: - From the home page you have to click on the charts option then hot 100-page link through code.##\n",
    "\n",
    "hot100=driver.find_element(By.XPATH, '//ul//li[1]//a[@class=\"c-link  lrv-a-unstyle-link lrv-u-color-brand-primary:hover lrv-a-hover-effect lrv-u-whitespace-nowrap lrv-u-color-grey-dark\"]')\n",
    "hot100.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "af3f3314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song Name</th>\n",
       "      <th>Artist Name</th>\n",
       "      <th>Last week rank</th>\n",
       "      <th>Peak rank</th>\n",
       "      <th>Weeks on board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Song Name, Artist Name, Last week rank, Peak rank, Weeks on board]\n",
       "Index: []"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song=[]\n",
    "for i in driver.find_elements(By.XPATH, '//h3[@class=\"c-title  a-no-trucate a-font-primary-bold-s u-letter-spacing-0021 lrv-u-font-size-18@tablet lrv-u-font-size-16 u-line-height-125 u-line-height-normal@mobile-max a-truncate-ellipsis u-max-width-330 u-max-width-230@tablet-only\"]'):\n",
    "    song.append(i.text)\n",
    "for i in driver.find_elements(By.XPATH, '//h3[@class=\"c-title  a-no-trucate a-font-primary-bold-s u-letter-spacing-0021 u-font-size-23@tablet lrv-u-font-size-16 u-line-height-125 u-line-height-normal@mobile-max a-truncate-ellipsis u-max-width-245 u-max-width-230@tablet-only u-letter-spacing-0028@tablet\"]'):\n",
    "    song.insert(0,i.text)\n",
    "    \n",
    "singer=[]\n",
    "for i in driver.find_elements(By.XPATH, '//span[@class=\"c-label  a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only\"]'):\n",
    "    singer.append(i.text)\n",
    "for i in driver.find_elements(By.XPATH, '//span[@class=\"c-label  a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only u-font-size-20@tablet\"]'):\n",
    "    singer.insert(0,i.text)\n",
    "    \n",
    "lastweek=[]\n",
    "for i in driver.find_elements(By.XPATH, '//li[4][@class=\"o-chart-results-list__item // a-chart-color u-width-72 u-width-55@mobile-max u-width-55@tablet-only lrv-u-flex lrv-u-flex-shrink-0 lrv-u-align-items-center lrv-u-justify-content-center lrv-u-border-b-1 u-border-b-0@mobile-max lrv-u-border-color-grey-light u-background-color-white-064@mobile-max u-hidden@mobile-max\"]//span[@class=\"c-label  a-font-primary-m lrv-u-padding-tb-050@mobile-max\"]'):\n",
    "    lastweek.append(i.text)\n",
    "for i in driver.find_elements(By.XPATH, '//li[4][@class=\"o-chart-results-list__item // a-chart-color u-width-72 u-width-55@mobile-max u-width-55@tablet-only lrv-u-flex lrv-u-flex-shrink-0 lrv-u-align-items-center lrv-u-justify-content-center lrv-u-border-b-1 u-border-b-0@mobile-max lrv-u-border-color-grey-light u-background-color-white-064@mobile-max u-hidden@mobile-max\"]//span[@class=\"c-label  a-font-primary-bold-l a-font-primary-m@mobile-max u-font-weight-normal@mobile-max lrv-u-padding-tb-050@mobile-max u-font-size-32@tablet\"]'):\n",
    "    lastweek.insert(0,i.text)\n",
    "    \n",
    "peak=[]\n",
    "for i in driver.find_elements(By.XPATH, '//li[5][@class=\"o-chart-results-list__item // a-chart-bg-color a-chart-color u-width-72 u-width-55@mobile-max u-width-55@tablet-only lrv-u-flex lrv-u-flex-shrink-0 lrv-u-align-items-center lrv-u-justify-content-center lrv-u-background-color-grey-lightest lrv-u-border-b-1 u-border-b-0@mobile-max lrv-u-border-color-grey-light u-hidden@mobile-max\"]//span'):\n",
    "    peak.append(i.text)\n",
    "\n",
    "weak=[]\n",
    "for i in driver.find_elements(By.XPATH, '//li[6][@class=\"o-chart-results-list__item // a-chart-color u-width-72 u-width-55@mobile-max u-width-55@tablet-only lrv-u-flex lrv-u-flex-shrink-0 lrv-u-align-items-center lrv-u-justify-content-center lrv-u-border-b-1 u-border-b-0@mobile-max lrv-u-border-color-grey-light u-background-color-white-064@mobile-max u-hidden@mobile-max\"]//span'):\n",
    "    weak.append(i.text)\n",
    "\n",
    "que6=pd.DataFrame({'Song Name':song,'Artist Name':singer,'Last week rank':lastweek,'Peak rank':peak,'Weeks on board':weak})\n",
    "que6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10262378",
   "metadata": {},
   "source": [
    "6. Scrape the details of Highest sellingnovels.\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey\u0002compare/\n",
    "You have to find the following details:\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c6c6fe46",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9b37e9d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Volume Sales</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book Name       Author Name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volume Sales        Publisher                        Genre  \n",
       "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152       Bloomsbury           Children's Fiction  \n",
       "2     4,200,654       Bloomsbury           Children's Fiction  \n",
       "3     4,179,479       Bloomsbury           Children's Fiction  \n",
       "4     3,758,936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "95      807,311     Random House   General & Literary Fiction  \n",
       "96      794,201          Penguin        Food & Drink: General  \n",
       "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98      791,507            Orion           Biography: General  \n",
       "99      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book=[]\n",
    "for i in driver.find_elements(By.XPATH, '//tbody//tr//td[2]'):\n",
    "    book.append(i.text)\n",
    "    \n",
    "author=[]\n",
    "for i in driver.find_elements(By.XPATH, '//tbody//tr//td[3]'):\n",
    "    author.append(i.text)\n",
    "    \n",
    "volume=[]\n",
    "for i in driver.find_elements(By.XPATH, '//tbody//tr//td[4]'):\n",
    "    volume.append(i.text)\n",
    "    \n",
    "publisher=[]\n",
    "for i in driver.find_elements(By.XPATH, '//tbody//tr//td[5]'):\n",
    "    publisher.append(i.text)\n",
    "    \n",
    "genre=[]\n",
    "for i in driver.find_elements(By.XPATH, '//tbody//tr//td[6]'):\n",
    "    genre.append(i.text)\n",
    "    \n",
    "que8=pd.DataFrame({'Book Name':book,'Author Name':author,'Volume Sales':volume,'Publisher':publisher,'Genre':genre})\n",
    "que8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c045b03",
   "metadata": {},
   "source": [
    "7. Scrape the details most watched tv series of all time from imdb.com. \n",
    "Url = https://www.imdb.com/list/ls095964455/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1fb3c777",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.imdb.com/list/ls095964455/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dfb2f8da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year Span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,119,869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016–2024)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,208,557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1,005,165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>296,708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>255,664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.4</td>\n",
       "      <td>50,674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>62,559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005– )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>202,485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.1</td>\n",
       "      <td>42,005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>250,278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year Span                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things  (2016–2024)    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)                     Drama   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds     (2005– )     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "    Runtime Rating      Votes  \n",
       "0    57 min    9.2  2,119,869  \n",
       "1    51 min    8.7  1,208,557  \n",
       "2    44 min    8.1  1,005,165  \n",
       "3    60 min    7.5    296,708  \n",
       "4    43 min    7.6    255,664  \n",
       "..      ...    ...        ...  \n",
       "95   42 min    7.4     50,674  \n",
       "96   50 min    7.8     62,559  \n",
       "97   42 min    8.1    202,485  \n",
       "98   45 min    7.1     42,005  \n",
       "99  572 min    8.6    250,278  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name=[]\n",
    "for i in driver.find_elements(By.XPATH, '//h3//a'):\n",
    "    name.append(i.text)\n",
    "\n",
    "year=[]\n",
    "for i in driver.find_elements(By.XPATH, '//h3//span[@class=\"lister-item-year text-muted unbold\"]'):\n",
    "    year.append(i.text)\n",
    "    \n",
    "genre=[]\n",
    "for i in driver.find_elements(By.XPATH, '//p//span[@class=\"genre\"]'):\n",
    "    genre.append(i.text)\n",
    "    \n",
    "runtime=[]\n",
    "for i in driver.find_elements(By.XPATH, '//p//span[@class=\"runtime\"]'):\n",
    "    runtime.append(i.text)\n",
    "    \n",
    "rating=[]\n",
    "for i in driver.find_elements(By.XPATH, '//div[@class=\"ipl-rating-star small\"]//span[@class=\"ipl-rating-star__rating\"]'):\n",
    "    rating.append(i.text)\n",
    "    \n",
    "vote=[]\n",
    "for i in driver.find_elements(By.XPATH, '//span[@name=\"nv\"]'):\n",
    "    vote.append(i.text)\n",
    "    \n",
    "que9=pd.DataFrame({'Name':name,'Year Span':year,'Genre':genre,'Runtime':runtime,'Rating':rating,'Votes':vote})\n",
    "que9\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6335aa5b",
   "metadata": {},
   "source": [
    "8. Details of Datasets from UCI machine learning repositories. \n",
    "Url = https://archive.ics.uci.edu/\n",
    "You have to find the following details:\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute\n",
    "G) Year\n",
    "Note: - from the home page you have to go to the ShowAllDataset page through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fd4f3979",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://archive.ics.uci.edu/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c7c561a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: - from the home page you have to go to the ShowAllDataset page through code\n",
    "\n",
    "all=driver.find_element(By.XPATH, '//span[@class=\"whitetext\"]//b')\n",
    "all.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "14301088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Default Task</th>\n",
       "      <th>Attribute Type</th>\n",
       "      <th>Instances</th>\n",
       "      <th>Attributes</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abalone</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>4177</td>\n",
       "      <td>8</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annealing</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>798</td>\n",
       "      <td>38</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anonymous Microsoft Web Data</td>\n",
       "      <td></td>\n",
       "      <td>Recommender-Systems</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>37711</td>\n",
       "      <td>294</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arrhythmia</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>452</td>\n",
       "      <td>279</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>Influenza outbreak event prediction via Twitte...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>75840</td>\n",
       "      <td>525</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>Turkish Music Emotion Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>400</td>\n",
       "      <td>50</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>Maternal Health Risk Data Set</td>\n",
       "      <td></td>\n",
       "      <td>Classification</td>\n",
       "      <td></td>\n",
       "      <td>1014</td>\n",
       "      <td>7</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>Room Occupancy Estimation</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>10129</td>\n",
       "      <td>16</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>Image Recognition Task Execution Times in Mobi...</td>\n",
       "      <td>Univariate</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>4000</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>622 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Name  \\\n",
       "0                                              Abalone   \n",
       "1                                                Adult   \n",
       "2                                            Annealing   \n",
       "3                         Anonymous Microsoft Web Data   \n",
       "4                                           Arrhythmia   \n",
       "..                                                 ...   \n",
       "617  Influenza outbreak event prediction via Twitte...   \n",
       "618                      Turkish Music Emotion Dataset   \n",
       "619                      Maternal Health Risk Data Set   \n",
       "620                          Room Occupancy Estimation   \n",
       "621  Image Recognition Task Execution Times in Mobi...   \n",
       "\n",
       "                      Data Type          Default Task  \\\n",
       "0                 Multivariate        Classification    \n",
       "1                 Multivariate        Classification    \n",
       "2                 Multivariate        Classification    \n",
       "3                                Recommender-Systems    \n",
       "4                 Multivariate        Classification    \n",
       "..                          ...                   ...   \n",
       "617               Multivariate        Classification    \n",
       "618               Multivariate        Classification    \n",
       "619                                   Classification    \n",
       "620  Multivariate, Time-Series        Classification    \n",
       "621                 Univariate            Regression    \n",
       "\n",
       "                  Attribute Type Instances Attributes   Year  \n",
       "0    Categorical, Integer, Real      4177          8   1995   \n",
       "1          Categorical, Integer     48842         14   1996   \n",
       "2    Categorical, Integer, Real       798         38          \n",
       "3                   Categorical     37711        294   1998   \n",
       "4    Categorical, Integer, Real       452        279   1998   \n",
       "..                           ...       ...        ...    ...  \n",
       "617               Integer, Real     75840        525   2020   \n",
       "618               Integer, Real       400         50   2020   \n",
       "619                                  1014          7   2020   \n",
       "620                        Real     10129         16   2021   \n",
       "621                        Real      4000          2   2021   \n",
       "\n",
       "[622 rows x 7 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name=[]\n",
    "for i in driver.find_elements(By.XPATH, '//b//a'):\n",
    "    name.append(i.text)\n",
    "    \n",
    "tyep=[]\n",
    "for i in driver.find_elements(By.XPATH, '/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[2]'):\n",
    "    tyep.append(i.text)\n",
    "tyep.pop(0)\n",
    "\n",
    "task=[]\n",
    "for i in driver.find_elements(By.XPATH, '/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[3]'):\n",
    "    task.append(i.text)\n",
    "task.pop(0)\n",
    "\n",
    "att_type=[]\n",
    "for i in driver.find_elements(By.XPATH, '/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[4]'):\n",
    "    att_type.append(i.text)\n",
    "att_type.pop(0)\n",
    "\n",
    "inst=[]\n",
    "for i in driver.find_elements(By.XPATH, '/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[5]'):\n",
    "    inst.append(i.text)\n",
    "inst.pop(0)\n",
    "\n",
    "att=[]\n",
    "for i in driver.find_elements(By.XPATH, '/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[6]'):\n",
    "    att.append(i.text)\n",
    "att.pop(0)\n",
    "\n",
    "year=[]\n",
    "for i in driver.find_elements(By.XPATH, '/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[7]'):\n",
    "    year.append(i.text)\n",
    "year.pop(0)\n",
    "\n",
    "que10=pd.DataFrame({'Name':name,'Data Type':tyep,'Default Task':task,'Attribute Type':att_type,'Instances':inst,'Attributes':att,'Year':year})\n",
    "que10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7618631d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
